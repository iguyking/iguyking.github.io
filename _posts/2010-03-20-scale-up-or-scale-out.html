---
layout: post
status: publish
published: true
title: Scale Up or Scale Out&trade;
author:
  display_name: iguy
  login: iguy
  email: iguy@ionsphere.org
  url: ''
author_login: iguy
author_email: iguy@ionsphere.org
wordpress_id: 380
wordpress_url: http://itsjustanotherlayer.com/?p=380
date: !binary |-
  MjAxMC0wMy0yMCAyMjo0MjozNCAtMDUwMA==
date_gmt: !binary |-
  MjAxMC0wMy0yMSAwMzo0MjozNCAtMDUwMA==
categories:
- VMware
tags:
- capacity
- hypervisor
- ScaleOut
- ScaleUp
- VMware
comments:
- id: 104
  author: PiroNet
  author_email: pironet@hotmail.com
  author_url: http://deinoscloud.wordpress.com
  date: !binary |-
    MjAxMC0wMy0yMSAwNjo0OTo0MyAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wMy0yMSAxMTo0OTo0MyAtMDUwMA==
  content: ! 'Hi Ian,


    You put fimware management is an issue with BL495, can you elaborate?


    I''ve read Duncan''s post as well, my though is that since virtualization came
    into the game, the notion of ''all eggs in a single basket'' is blured, the boudaries
    are dynamic and expanding out (vs stretching in). Yesterday you would be flamed
    down if you say that you run 3 VMs on a single host. Today people would say that''s
    a waste of resources.


    We could get a math geek in and compute the probability, my bet is that scaling
    out at the same time you scale up decreases significantly the risk associated
    with all in one basket, don''t you ?'
- id: 105
  author: Craig
  author_email: lfchin@gmail.com
  author_url: http://malaysiavm.com
  date: !binary |-
    MjAxMC0wMy0yMSAwOTowNzo0NSAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wMy0yMSAxNDowNzo0NSAtMDUwMA==
  content: 1 think you may need to compare with are the HA capability. Generally before
    virtualization in place, all the standalone machine do not entitle the cluster
    features which allow them to prevent hardware failure. A part replacement for
    standalone system could take up few hours easily before it could up and running
    again. Even you have 30 VM down at 1 time, and fully restarted within next 15
    mins, you are still provide a better SLA to the business. If they need more uptime,
    you can upsell the FT, or operating system cluster on top of the OS layer in the
    virtual machine. Just my 2 cents.
- id: 106
  author: iguy
  author_email: iguy@ionsphere.org
  author_url: http://www.itsjustanotherlayer.com
  date: !binary |-
    MjAxMC0wMy0yMiAwOTozMDo1MCAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wMy0yMiAxNDozMDo1MCAtMDUwMA==
  content: ! "@PiroNet Firmware management on the blade chassis is a major challenge
    if you have a variety of systems running on there, say 8 or 16 or 32 depending
    on your blades in it.   In order to update the Onboard Administrator or Virtual
    Connect Firmwares you must first update the BIOS on all of the blades, then you
    can update the iLOs and then the OA and then the VC.   In an enterprise environment,
    you can't easily get a single maintenance zone to take down 8 or 32 systems so
    this can take months at best with scheduling and organization.   So you encounter
    an issue with the VC or OA (which has happened several times to me in the past
    year) which is fixed in an update of the firmware.   Yet that update doesn't support
    the iLO 1.70 that I'm running currently and if I update that iLO to 1.78 for supported
    version of the OA that I'm going to fix the issue in VC, I have known issue with
    the BIOS version so I have to update that.    It is a complete domino system that
    is very difficult to work with.  \n\nNow if I ran VMware on all the blades in
    a single chassis it wouldn't be nearly as big of a deal as long as I design to
    prevent too many eggs in a single basket.   Regardless of how redundant something
    is, it will go down.  Not a matter of if, just a matter of when.   Hopefully you
    never see that day, yet when that day comes are you willing to take the fall for
    that design?   So to do a serious VMware cluster you want to spread a given cluster
    across multiple chassis at a bare minimum.   That's not exactly cheap at the end
    of the day unless your buying 16 BL495s at the get go and don't mind having the
    risk of 1&#47;2 of an 8 host cluster going down at any given time.   This would
    address the single point of failure discussion.   \n\nThe \"Eggs in a Basket\"
    is not blurred.  It is still very clear.  Virtualization does not suddenly add
    more capabilities to the guest OSes.   Just because it is virtual doesn't mean
    you don't have single points of failure.   The virtual is just another layer in
    the discussion.   VMs run in a single location at any given time.   They are the
    point of impact for an IaaS environment concept.  \n\nMy math and statistics have
    shown so far that scaling out does reduce our overall system impact at time of
    outage event.   It does cost more though in the grand scheme if you don't calculate
    in the outage impact to your business or clients.   That can often even the cost
    discussion pretty quickly when a given VM is down for more than 15 mins cause
    it takes 30 mins to come or something and that runs the business $200k&#47;hour
    in lost sales.   Then well.. having 2 more hosts out there instead of 1 big host,
    sure can make that discussion moot quickly."
- id: 107
  author: iguy
  author_email: iguy@ionsphere.org
  author_url: http://www.itsjustanotherlayer.com
  date: !binary |-
    MjAxMC0wMy0yMiAwOTozNzo0NyAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wMy0yMiAxNDozNzo0NyAtMDUwMA==
  content: ! "@Craig HA just means you can return to service automatically and hopefully
    faster.   We do provide better uptime with VMware products.   We have proven this
    time and time again.   This however doesn't negate the level of overall impact
    when I loose a host with 60 VMs on it.   It takes time to bring them back up,
    to get the applications working properly again etc.   I would love to upsell FT
    and will for some apps once it can support 2 vCPUs at a time.    \n\nAs for adding
    a tack on Operating System Cluster on top of that actually has caused more outages
    than it helps for most of these apps.  It adds extra complexity to a running application
    for what?   Return to service faster?  VMware HA is what we use for that.  \n\nThis
    is often resolved by finding the reason a given application can not handle a hard
    crash and working on getting that fixed so it can restart cleaner in a crash state.
    \ \n\nThe thing to think about is when 60 business facing critical applications
    go down at one time, that's not just a single Severity Priority 1 ticket, its
    60.   That's a huge hit on the reputation.   Not a good thing.   We can stomach
    30 a little easier.   Especially when you talk about the fact that I saved $500k
    by sticking all these critical apps into VMware.   We can do the numbers and compare
    outage costs for these applications versus the capital and operational costs of
    the Infrastructure.    If an app costs the company $100k&#47;hour in lost sales
    and we only saved $20k per year.... Not a really good trade off if it goes down.
    \  We have to balance the impact."
- id: 108
  author: ! 'Virtualization Short Take #37 - blog.scottlowe.org - The weblog of an
    IT pro specializing in virtualization, storage, and servers'
  author_email: ''
  author_url: http://blog.scottlowe.org/2010/03/24/virtualization-short-take-37/
  date: !binary |-
    MjAxMC0wMy0yNCAwODo1MDoxMSAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wMy0yNCAxMzo1MDoxMSAtMDUwMA==
  content: ! '[...] ages-old discussion of scale up vs. scale out is revisited again
    in this blog post. I guess the key takeaway for me is the reminder that while
    VMware HA does restart workloads [...]'
- id: 109
  author: The View from the Other Side - blog.scottlowe.org - The weblog of an IT
    pro specializing in virtualization, storage, and servers
  author_email: ''
  author_url: http://blog.scottlowe.org/2010/04/03/the-view-from-the-other-side/
  date: !binary |-
    MjAxMC0wNC0wMyAwMjoxNzoxMCAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wNC0wMyAwNzoxNzoxMCAtMDUwMA==
  content: ! '[...] caught Steve&#8217;s eye: The ages-old discussion of scale up
    vs. scale out is revisited again in this blog post. I guess the key takeaway for
    me is the reminder that while VMware HA does restart workloads [...]'
- id: 110
  author: The View from the Other Side | Free Techie Blog
  author_email: ''
  author_url: http://www.freetechie.com/blog/the-view-from-the-other-side/
  date: !binary |-
    MjAxMC0wNC0wNiAxNjozMDozNSAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wNC0wNiAyMTozMDozNSAtMDUwMA==
  content: ! '[...] caught Steve&#8217;s eye: The ages-old discussion of scale up
    vs. scale out is revisited again in this blog post. I guess the key takeaway for
    me is the reminder that while VMware HA does restart workloads [...]'
- id: 111
  author: All things virtual VIII &laquo; TheSaffaGeek
  author_email: ''
  author_url: http://thesaffageek.wordpress.com/?p=107
  date: !binary |-
    MjAxMC0wNC0xNiAwNjo0Mjo0MCAtMDUwMA==
  date_gmt: !binary |-
    MjAxMC0wNC0xNiAxMTo0Mjo0MCAtMDUwMA==
  content: ! '[...] scaling up due to the release of the new Intel 5600 series that
    has six cores. Which set off a blog posting by Ian Koenig at http:&#47;&#47;itsjustanotherlayer.com&#47;
    titled scale up or scale out in which he brings up [...]'
- id: 112
  author: this scale up versus scale out business? &laquo; vmwareukseteam
  author_email: ''
  author_url: http://vmwareukseteam.wordpress.com/2010/12/14/this-scale-up-versus-scale-out-business/
  date: !binary |-
    MjAxMC0xMi0xNCAxMjowNDozNiAtMDYwMA==
  date_gmt: !binary |-
    MjAxMC0xMi0xNCAxODowNDozNiAtMDYwMA==
  content: ! '[...] http:&#47;&#47;itsjustanotherlayer.com&#47;2010&#47;03&#47;scale-up-or-scale-out%E2%84%A2&#47;
    [...]'
---
<p>Duncan over at <a title="Scale Up" href="http:&#47;&#47;www.yellow-bricks.com&#47;2010&#47;03&#47;17&#47;scale-up&#47;" target="_blank">Yellow-Bricks.com<&#47;a> brings up the great discussion once again.&nbsp;&nbsp; Every time&nbsp; a brand new piece of hardware comes out with more RAM possible or better, faster CPUs I have the "<em><strong>Scale Up or Scale Out&trade;<&#47;strong><&#47;em>" Discussion with many people.&nbsp; I have this discussion every 9-12 months on average.&nbsp; We end up covering all sorts of criteria on what to compare and what is acceptable and what is not.</p>
<p>Our conversation usually goes something like this:</p>
<blockquote><p>The hot new badness just came out and we need to order more hardware.</p>
<p>Awesome.&nbsp;&nbsp; So how much does this puppy have in it?&nbsp; RAM?&nbsp; CPUs?&nbsp;&nbsp; Slots for HBAs &amp; NICs?</p>
<p>Did you know the new motherboard comes with 4 NICs now so our standard config can go from 4U to 2U and gobs of RAM with 6 core CPUs now.</p>
<p>Awesome!&nbsp;&nbsp; *pause*&nbsp; You know with that much RAM I can put 100 Win7 VDI systems on there.&nbsp;&nbsp; Umm.. What about when it goes down?</p>
<p>Oh.. Hrm.&nbsp;&nbsp; That wouldn't be so good.&nbsp;&nbsp; ....<&#47;blockquote><br />
That being said we generally end up breaking it down to a couple of factors.</p>
<ol>
<li>What is the current capacity configuration we run with today?<&#47;li>
<li>What is our current pain points in CPU, Memory, Network or Storage?<&#47;li>
<li>Is there any new architecture changes coming that will impact this design?&nbsp;&nbsp; Is there a new switch fabric that needs to be plugged into?&nbsp;&nbsp; Is there changes to storage that need to be addressed?<&#47;li>
<li>How much does this new hardware configuration cost?<&#47;li>
<li>How will this change affect DRS's Chaos Theory?&nbsp; The more hosts, the more DRS can do for you due to Chaos theory.<&#47;li>
<li>What is our Risk level for number of eggs in a single basket?<&#47;li><br />
<&#47;ol><br />
The point is most corporation's environments aren't starting from scratch.&nbsp; In my case we have a known configuration today to use as a baseline and adjust the environment and design every hardware order to make it better.</p>
<p>In our most recent order we had this discussion all over again.&nbsp; This time we had some architectural changes needed to prevent some false positive HA events from happening in a 2 time a year strange events.&nbsp;&nbsp; So we are going to a 3 switch connectivity solution to enable network beacon for NIC teamed connections.&nbsp; We started with the following information:</p>
<ul>
<li>Baseline:&nbsp; HP DL585 G5, 4 sockets w&#47; quad cores, 128G of RAM, 3 Dual 1G NICs, 2 Emulex LPe11000 HBAs<&#47;li>
<li>Cluster: 10 Host Clusters with ~30 per Host in Servers and ~65 Workstations per Host in View<&#47;li>
<li>Pain Points:&nbsp; CPU starvation, Licensing Issues with 10 Host sized clusters<&#47;li>
<li>Risk Level:&nbsp; Politically we are getting pretty touchy about more than 30 Servers going down in a single blow even if HA works on bringing them up in under 15 mins automatically.<&#47;li><br />
<&#47;ul><br />
We compared 3 different models of newer, faster, badder and more wicked hardware from HP since the DL585 G5s are not really on the manufacturing line anymore.&nbsp;&nbsp; So we looked at the BL495cG6, DL585 G6, DL385 G6 and DL580 G6.</p>
<p>DL585 G6:</p>
<ul>
<li>Pros
<ul>
<li>Proven and comfortable AMD based stable platform with a good price&#47;performance cost.<&#47;li>
<li>Gain more CPU resources with the additional 2 cores per socket.&nbsp; 6 core systems.<&#47;li>
<li>Can build 5 Host clusters to address licensing issues.&nbsp;&nbsp; Issues with HA  support for the density involved.<&#47;li><br />
<&#47;ul><br />
<&#47;li></p>
<li>Cons
<ul>
<li>Same Risk Level as before.<&#47;li><br />
<&#47;ul><br />
Push</p>
<ul>
<li>Same architectural solution today with maybe another NIC card to enable   the NIC Beaconing<&#47;li><br />
<&#47;ul><br />
<&#47;li><br />
<&#47;ul><br />
DL580 G5:</p>
<ul>
<li>Pros
<ul>
<li>Fastest individual cores out there.&nbsp;&nbsp; Lots of good press about the Intel.<&#47;li>
<li>Should get better CPU resources with higher performing CPUs.<&#47;li>
<li>Can build 5 Host clusters to address licensing issues.&nbsp;&nbsp; Issues with HA support for the density involved.<&#47;li><br />
<&#47;ul><br />
<&#47;li></p>
<li>Cons
<ul>
<li>Significant premium in cost for speed.&nbsp;&nbsp; See easily a 25% premium for a 10% faster performance.<&#47;li>
<li>Same Risk Level as before.<&#47;li><br />
<&#47;ul><br />
<&#47;li></p>
<li>Push
<ul>
<li>Same architectural solution today with maybe another NIC card to enable    the NIC Beaconing.<&#47;li><br />
<&#47;ul><br />
<&#47;li><br />
<&#47;ul><br />
DL385 G6:</p>
<ul>
<li>Pros
<ul>
<li>Lowers the risk level without lowering performance<&#47;li>
<li>Best price&#47;performance cost for 6 core systems<&#47;li>
<li>Has enough slots to move to the newer network layout to enable NIC Beaconing<&#47;li>
<li>Gain more CPU resources with the additional 2 cores per socket.&nbsp; 6 core  systems.<&#47;li>
<li>Put 64G of RAM into them and build 5 host clusters for licensing problematic applications.<&#47;li><br />
<&#47;ul><br />
<&#47;li></p>
<li>Cons
<ul>
<li>More physical hosts to deal with (cabling, power, rack space, cooling, management)<&#47;li><br />
<&#47;ul><br />
<&#47;li><br />
<&#47;ul><br />
BL495c G6:</p>
<ul>
<li>Pros
<ul>
<li>Blades reduce the amount of cabling<&#47;li><br />
<&#47;ul></p>
<ul>
<li>Gain more CPU resources with the additional 2 cores per socket.&nbsp; 6  core  systems<&#47;li><br />
<&#47;ul><br />
<&#47;li></p>
<li>Cons
<ul>
<li>Firmware Management is an issue<&#47;li>
<li>Increases our Risk Level with more eggs in the same basket unless we get multiple chassis to spread the blades across<&#47;li>
<li>New solution from the ground up running ESX on blades<&#47;li>
<li>Not ready to support Flex10 and because of this we have limited NIC capabilities to fit our requirements<&#47;li><br />
<&#47;ul><br />
<&#47;li><br />
<&#47;ul><br />
We decided to go with the DL385 G6s based on these criteria.&nbsp; We will dedicate a specific 5 Host cluster for problem children applications with licensing issues.&nbsp;&nbsp; The RAM size of the hosts will limit the number of VMs we can end up putting in a cluster which addresses the Risk Level of number of VMs per Host.&nbsp; We are still <strong>way<&#47;strong> ahead of the game using VMware so having to have a couple more physicals for all these improvements is not an issue.</p>
<p>In your  company or solution something else may be more appropriate.&nbsp; The key in an ongoing improvement mentality is have things you can measure and then criteria on what to change along with why. &nbsp; There is no  one size fits all answer which is why VMware works so well for so many  different folks.&nbsp;&nbsp; We don't have to change how we do things to gain a  lot of flexibility in the Datacenter while not changing how we ultimately end up managing these systems.</p>
